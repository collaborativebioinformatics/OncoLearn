tokenizer:
  _target_: bmfm_targets.config.TokenizerConfig
  identifier: all_genes
data_module:
  _target_: bmfm_targets.datasets.cellxgene.CellXGeneNexusDataModule
  _partial_: true
  num_workers: 8
  mlm: true
  collation_strategy: multitask
  shuffle: true
  change_ratio: 0.15
  mask_ratio: 0.95
  max_length: 4096
  sequence_order: random
  switch_ratio: 0.0
  batch_size: 8
  limit_genes: protein_coding
  log_normalize_transform: true
  pad_zero_expression_strategy: batch_wise
  dataset_kwargs:
    uri: /proj/bmfm/omics/data/scRNA/cellxgene/2025-01-30/soma/
    index_dir: /proj/bmfm/omics/data/scRNA/cellxgene/2025-01-30/cellxgene_equal_downsample_1pct_nexus_index/
    expose_zeros: all
    raw_counts: true
label_columns:
- _target_: bmfm_targets.config.LabelColumnInfo
  label_column_name: cell_type
- _target_: bmfm_targets.config.LabelColumnInfo
  label_column_name: tissue
- _target_: bmfm_targets.config.LabelColumnInfo
  label_column_name: tissue_general
- _target_: bmfm_targets.config.LabelColumnInfo
  label_column_name: donor_id
  gradient_reversal_coefficient: 1.0
fields:
- _target_: bmfm_targets.config.FieldInfo
  field_name: genes
  pretrained_embedding: null
  is_masked: true
  vocab_update_strategy: static
  decode_modes:
    - token_scores
- _target_: bmfm_targets.config.FieldInfo
  field_name: expressions
  is_masked: true
  tokenization_strategy: continuous_value_encoder
  continuous_value_encoder_kwargs:
    kind: mlp_with_special_token_embedding
    zero_as_special_token: true
  decode_modes:
    - regression
    - is_zero
task:
  _target_: bmfm_targets.config.TrainingTaskConfig
  default_root_dir: ${oc.env:BMFM_TARGETS_TRAINING_DIR}/1pct_equal_downsample/
  max_epochs: 20
  precision: 16-mixed
  val_check_interval: 4000
  gradient_clip_val: 0.5
  accelerator: gpu
  max_steps: -1
  tf32_mode: medium
  accumulate_grad_batches: 4
  freeze_layers: false
  resume_training_from_ckpt: true
  checkpoints_every_n_train_steps: 10000
  limit_val_batches: 1024
trainer:
  _target_: bmfm_targets.config.TrainerConfig
  batch_size: ${data_module.batch_size}
  warmup_steps: 1000
  weight_decay: 0.01
  learning_rate: 0.0001
  betas:
  - 0.9
  - 0.99
  epsilon: 1.0e-08
  lr_decay_steps: null
  losses:
  - label_column_name: cell_type
    weight: 1
    name: focal
    focal_gamma: 2
  - label_column_name: tissue
    weight: 1
    name: focal
    focal_gamma: 2
  - label_column_name: tissue_general
    weight: 1
    name: focal
    focal_gamma: 2
  - label_column_name: donor_id
    weight: 0.05
    name: focal
    focal_gamma: 2
  - field_name: expressions
    name: mse
    ignore_zero: true
  - field_name: expressions
    name: is_zero_bce
    weight: 1.5
  - field_name: genes
    name: cross_entropy
    weight: 0.7
  batch_prediction_behavior: track
model:
  _target_: bmfm_targets.config.SCBertConfig
  _partial_: true
  num_hidden_layers: 12
  num_attention_heads: 12
  intermediate_size: 3072
  hidden_act: gelu
  hidden_size: 768
  hidden_dropout_prob: 0.1
  attention_probs_dropout_prob: 0.1
  initializer_range: 0.02
  layer_norm_eps: 1.0e-12
  pad_token_id: 0
  use_cache: true
  attention: torch
  checkpoint: null # warmup checkpoint, trained on mlm only
track_clearml:
  project_name: bmfm-targets
  task_name: mlm.multitask.v1
  continue_last_task: true
seed:
  seed_value: 1234
